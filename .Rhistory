model4_MSE <- mean((test_time -model4_pred)^2)
model4_RMSE <- sqrt(mean((test_time -model4_pred)^2))
model4_MAE <- mean(abs(test_time -model4_pred))
#kaggle scale
kaggle_scale <- c(0.76794, 0.75385, 0.77033,0.77272)
# The final result
The_final_table <- data.frame(
Test = c("MSE", "RMSE", "MAE", "Kaggle Scale"),
Model_1_lm = c(model1_MSE, model1_RMSE, model1_MAE, kaggle_scale[1]),
Model_1_glm = c(model2_MSE, model2_RMSE, model2_MAE, kaggle_scale[2]),
Model_2_lm = c(model3_MSE, model3_RMSE, model3_MAE, kaggle_scale[3]),
Model_2_glm = c(model4_MSE, model4_RMSE, model4_MAE, kaggle_scale[4])
)
# Print the final result
print(The_final_table)
#transfer the survived into factor
TTD$Survived <- as.factor(TTD$Survived)
#using the k ford cross validation to determine the number mtry win the
control <- trainControl(method="cv", number=10, search="grid", allowParallel = TRUE)
library(tidyverse)
library(dplyr)
library(fpp2)
library(glmnet)
library(tidyr)
library(lmtest)
library(boot)
library(forecast)
library(readr)
library(ggfortify)
library(tseries)
library(urca)
library(readxl)
library( lubridate)
library(tsbox)
library(RColorBrewer)
library(wesanderson)
library(writexl)
library(gridExtra)
library(vars)
library(leaps)
library(broom)
library(fastDummies)
library(car)
library(randomForest)
library(caret)
#model 2: the randomForest
############
############data import and cleaning
#clean the enviroment and import the date
rm( list = ls())
#setting the saving addreess
setwd("/Users/tie/Documents/GitHub/The-data-analysis-job--")
#####################
#Step one: Clean the data
#####################
Titanic_train_raw <- read_csv("Titanic data/train.csv",
col_types = cols( Name = col_skip(), Ticket = col_skip(),
Cabin = col_skip()))
#At here I skiped their name which does not impact the model training,
#their ticket number with is not important and their cabin which has limit number
################ The age.
#I notice there are some age part are empty so i decided to use mean of age to fill the gap.
#but before that I just need to check the distribution of age between the survived and died
#calcuate the average of all the age
######### fill the age
#calcuate the average age
The_average_age <- mean(Titanic_train_raw$Age, na.rm = TRUE)
#fill the NA age
Titanic_train_raw$Age[is.na(Titanic_train_raw$Age)] <- The_average_age
#outupt it into the aerage
Titanic_train_without_age_gap <- Titanic_train_raw
#remove towo empty line of embraketd
Titanic_train_cleaned <- na.omit(Titanic_train_without_age_gap)
#we got the final data
TTD <- dummy_cols(Titanic_train_cleaned, select_columns = "Sex", remove_selected_columns = TRUE)
#transfer the survived into factor
TTD$Survived <- as.factor(TTD$Survived)
#using the k ford cross validation to determine the number mtry win the
control <- trainControl(method="cv", number=10, search="grid", allowParallel = TRUE)
# Define a sequence of ntree values from 1 to 10
ntreeGrid <- expand.grid(mtry=1:10)
# Train the model across the ntree range
set.seed(123455632)
# Note: find the optimal setting for the mtry in the regression tree
model_test <- train(Survived ~ ., data=TTD, method="rf", trControl=control, tuneGrid=ntreeGrid)
print(model_test)
print(model_test)
library(randomForest)
library(caret) # For accuracy calculation
# Assuming TTD is your prepared dataset and it's ready for modeling
# Splitting data into training and test sets for evaluation
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(TTD$Survived, p = .8,
list = FALSE,
times = 1)
trainData <- TTD[trainIndex,]
testData <- TTD[-trainIndex,]
# Placeholder for storing model accuracy for each ntree value
ntree_accuracy <- data.frame(ntree = integer(), accuracy = numeric())
# Loop through a sequence of ntree values up to 10,000
for(ntree in seq(500, 10000, by = 500)) {
rf_model <- randomForest(Survived ~ ., data = trainData, ntree = ntree, mtry = 3)
# Make predictions on the test set
predictions <- predict(rf_model, newdata = testData)
# Calculate accuracy
accuracy <- sum(predictions == testData$Survived) / nrow(testData)
# Store the ntree and corresponding accuracy
ntree_accuracy <- rbind(ntree_accuracy, data.frame(ntree = ntree, accuracy = accuracy))
}
# Finding the optimal ntree value based on highest accuracy
optimal_ntree <- ntree_accuracy[which.max(ntree_accuracy$accuracy), ]
# Print the optimal ntree value and its accuracy
print(optimal_ntree)
library(randomForest)
library(caret) # For accuracy calculation
# Assuming TTD is your prepared dataset and it's ready for modeling
# Splitting data into training and test sets for evaluation
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(TTD$Survived, p = .8,
list = FALSE,
times = 1)
trainData <- TTD[trainIndex,]
testData <- TTD[-trainIndex,]
# Placeholder for storing model accuracy for each ntree value
ntree_accuracy <- data.frame(ntree = integer(), accuracy = numeric())
# Loop through a sequence of ntree values up to 10,000
for(ntree in seq(100, 10000, by = 500)) {
rf_model <- randomForest(Survived ~ ., data = trainData, ntree = ntree, mtry = 3)
# Make predictions on the test set
predictions <- predict(rf_model, newdata = testData)
# Calculate accuracy
accuracy <- sum(predictions == testData$Survived) / nrow(testData)
# Store the ntree and corresponding accuracy
ntree_accuracy <- rbind(ntree_accuracy, data.frame(ntree = ntree, accuracy = accuracy))
}
# Finding the optimal ntree value based on highest accuracy
optimal_ntree <- ntree_accuracy[which.max(ntree_accuracy$accuracy), ]
# Print the optimal ntree value and its accuracy
print(optimal_ntree)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 4100,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 4100,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
setwd("/Users/tie/Documents/GitHub/The-data-analysis-job--")
# Import test datast
test_data_set <- read_csv("Titanic data/test.csv",col_types = cols( Name = col_skip(), Ticket = col_skip(),
Cabin = col_skip()))
# Fill in missing Age with the average ag
test_data_set$Age <- replace(test_data_set$Age, is.na(test_data_set$Age), mean(test_data_set$Age, na.rm = TRUE))
#Transfer the test set into the dummy variable
test_data_ultra<- dummy_cols(test_data_set, select_columns = "Sex", remove_selected_columns = TRUE)
#generate the prediction
prediction <- predict(rf_model, newdata = test_data_ultra, type = "response")
# transfer it into 0 and 1, because the regression tree are give 1 and 2 as output.
bi_prediction <- as.integer(prediction) - 1
#put the Binary prediction into the test data set.
test_data_ultra$Survived <- bi_prediction
#the final output!
final_output_evil <- data.frame(PassengerId = test_data_ultra$PassengerId, Survived = test_data_ultra$Survived)
#write its down
write.csv(final_output_evil, "final_predictions_rf.csv", row.names = FALSE)
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(100:10000),  # Example ntree values
mtry = c(1:10))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
# Assuming TTD is your dataset ready for modeling
# First, specify your training control
control <- trainControl(method="cv", number=10, search="grid")
# Define the grid of parameters to search over
# Adjust the sequences as needed based on your dataset and computational considerations
ntreeGrid <- expand.grid(ntree = c(500, 1000, 5000, 10000),  # Example ntree values
mtry = c(2, 3, 4, 5, 6))  # Example mtry values, adjust based on your dataset
# Train the model using the 'train' function from the caret package
# Note: Ensure your target variable and predictors are appropriately formatted in TTD
model_test <- train(Survived ~ ., data=TTD,
method="rf",
trControl=control,
tuneGrid=ntreeGrid,
metric="Accuracy")
library(randomForest)
library(caret) # For accuracy calculation
# Assuming TTD is your prepared dataset and it's ready for modeling
# Splitting data into training and test sets for evaluation
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(TTD$Survived, p = .8,
list = FALSE,
times = 1)
trainData <- TTD[trainIndex,]
testData <- TTD[-trainIndex,]
# Placeholder for storing model accuracy for each ntree value
ntree_accuracy <- data.frame(ntree = integer(), accuracy = numeric())
# Loop through a sequence of ntree values up to 10,000
for(ntree in seq(100, 10000, by = 100)) {
rf_model <- randomForest(Survived ~ ., data = trainData, ntree = ntree, mtry = 3)
# Make predictions on the test set
predictions <- predict(rf_model, newdata = testData)
# Calculate accuracy
accuracy <- sum(predictions == testData$Survived) / nrow(testData)
# Store the ntree and corresponding accuracy
ntree_accuracy <- rbind(ntree_accuracy, data.frame(ntree = ntree, accuracy = accuracy))
}
# Finding the optimal ntree value based on highest accuracy
optimal_ntree <- ntree_accuracy[which.max(ntree_accuracy$accuracy), ]
# Print the optimal ntree value and its accuracy
print(optimal_ntree)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 200	,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000	,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000000,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
library(randomForest)
library(caret) # For accuracy calculation
# Assuming TTD is your prepared dataset and it's ready for modeling
# Splitting data into training and test sets for evaluation
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(TTD$Survived, p = .8,
list = FALSE,
times = 1)
trainData <- TTD[trainIndex,]
testData <- TTD[-trainIndex,]
# Placeholder for storing model accuracy for each ntree value
ntree_accuracy <- data.frame(ntree = integer(), accuracy = numeric())
# Loop through a sequence of ntree values up to 10,000
for(ntree in seq(100, 10000, by = 500)) {
rf_model <- randomForest(Survived ~ ., data = trainData, ntree = ntree, mtry = 3)
# Make predictions on the test set
predictions <- predict(rf_model, newdata = testData)
# Calculate accuracy
accuracy <- sum(predictions == testData$Survived) / nrow(testData)
# Store the ntree and corresponding accuracy
ntree_accuracy <- rbind(ntree_accuracy, data.frame(ntree = ntree, accuracy = accuracy))
}
# Finding the optimal ntree value based on highest accuracy
optimal_ntree <- ntree_accuracy[which.max(ntree_accuracy$accuracy), ]
# Print the optimal ntree value and its accuracy
print(optimal_ntree)
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
tree_1 <- getTree(rf_model, k = 1, labelVar=TRUE)
# This will print the structure of the tree in the console
print(tree_1)
#transfer the survived into factor
TTD$Survived <- as.factor(TTD$Survived)
#using the k ford cross validation to determine the number mtry win the
control <- trainControl(method="cv", number=10, search="grid", allowParallel = TRUE)
# Define a sequence of ntree values from 1 to 10
ntreeGrid <- expand.grid(mtry=1:10)
# Train the model across the ntree range
set.seed(123455632)
# Note: find the optimal setting for the mtry in the random forest
model_test <- train(Survived ~ ., data=TTD, method="rf", trControl=control, tuneGrid=ntreeGrid)
print(model_test)
Titanic_train_raw
TTD
TTD
model_test
#transfer the survived into factor
TTD$Survived <- as.factor(TTD$Survived)
#using the k ford cross validation to determine the number mtry win the
control <- trainControl(method="cv", number=10, search="grid", allowParallel = TRUE)
# Define a sequence of ntree values from 1 to 10
ntreeGrid <- expand.grid(mtry=1:10)
# Train the model across the ntree range
set.seed(123455632)
# Note: find the optimal setting for the mtry in the random forest
model_test <- train(Survived ~ ., data=TTD, method="rf", trControl=control, tuneGrid=ntreeGrid)
print(model_test)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
tree_1 <- getTree(rf_model, k = 1, labelVar=TRUE)
# This will print the structure of the tree in the console
print(tree_1)
# the optimual vaule for the mtry is 4
rf_model <- randomForest(Survived ~ ., data = TTD,
ntree = 10000,  #how many tree
mtry = 4, #the optimal
nodesize = 1, #1 for classficiation (die or live)
importance = TRUE)
print(rf_model)
